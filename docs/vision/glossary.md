---
id: "glossary"
type: vision
title: "Glossary"
status: active
owner: meta-agent
created: 2025-02-07
updated: 2026-02-22
refs:
  related: [manifesto, principles, arch-agent-architecture]
tags: [vision, language, reference]
---

# Glossary

Canonical term definitions for Syntropy OS. This is the shared language — use these terms consistently across all documents.

| Term | Definition |
|------|-----------|
| **Card** | The atomic unit of the system. Any actionable item presented as a card in the queue. |
| **Queue** | The ordered list of cards the user works through. Can be filtered by domain or project. |
| **Domain / Space** | A permanent, persistent container for an entire life area (My Condo, Career, Finances). Contains projects, tasks, reference info, artifacts, and a full event history. |
| **Project** | A time-bound effort within a Domain. Has tasks, a budget, a deadline, and completes when all tasks are done. Replaces "Epic" in earlier terminology. |
| **Dependency** | A relationship where Task B cannot be actioned until Task A is complete. |
| **Confidence** | A Probabilistic Agent's self-assessed probability that its suggested action is correct (0–100%). Produced by the agent's Skills, validated by a Deterministic Agent's Workflows, and presented to the Organic Agent's Internal Context for review. |
| **Threshold** | User-configurable confidence level above which AI auto-executes without asking. |
| **Event** | An immutable record of any action taken in the system. Append-only in Firestore. |
| **Audit Trail** | The browsable, filterable log of all events. |
| **Agent** | Any entity that participates in the system — a human (Organic Agent), an AI model (Probabilistic Agent), or a piece of code (Deterministic Agent). All agents share the same 9 Internal Components and interact through the same interfaces. In the product layer, "Domain Agents" (Email Agent, Finance Agent, Home Agent) are Probabilistic Agents with specialized Skills, Traits, and Policies for their domain. |
| **Quick Capture** | The multimodal input system (voice, text, photo) for rapid task creation. |
| **Materialized View** | A precomputed document (e.g., queue order, project stats) derived from the event log by Cloud Functions. |
| **Artifact** | Any uploaded or captured file (photo, PDF, voice memo, document) that has been processed by the AI extraction pipeline and linked to domains/projects/tasks. |
| **Surface** | A platform or interface through which users interact with the system (mobile app, web app, development platform). |
| **Decision Record** | A structured capture of any decision — the problem it solves, the options explored, what was decided, how to know it's working, and when to revisit. Decision records form a reasoning graph: they have hierarchy (parent/child), domain scope, and relationships to other decisions. Generalizes the ADR (Architecture Decision Record) pattern to all decision types: product, process, methodology, convention, principle. Classified as Type 1 (hard to reverse) or Type 2 (easily reversible). |
| **DRI** | Directly Responsible Individual — the agent (human or AI) that owns a domain and is accountable for its correctness. |
| **Observation** | A raw signal captured by any contributor — a friction, bug, idea, question, anxiety, pattern, need, praise, or any thought worth recording. Observations are the atomic unit of emergent intelligence: they accumulate, get structured retroactively, and are audited for patterns that inform system evolution. |
| **Upleveling** | The principle that every interaction and feedback loop should help contributors become more effective over time — better at expressing ideas, capturing observations, structuring thoughts, and contributing to the system — without creating dependency or learned helplessness. |
| **Reflection** | A special type of observation captured after completing work — a genuine, personal account of what the contributor experienced: what worked, what was hard, how it felt, what they'd need next time. Not a system design exercise or retrospective about others, but honest self-noticing that feeds the observation system as signal. |
| **Pulse Companion** | A personalized work companion agent that grows alongside each contributor — starting as a reflection assistant (helping articulate experience through context-aware questions) and evolving by emergence into a full work ally that understands behavior patterns, supports effectiveness, and collaborates across contributors to surface collective signals for system evolution. |
| **Reasoning Graph** | The interconnected graph of decision records that explains why everything in the system is the way it is. Traversable by hierarchy (problem stack), domain, and relationships. The reasoning graph is what would allow rebuilding the system from scratch — not identical, but with the same informed choices. |
| **Revisit Trigger** | A condition defined in a decision record that, when met, signals the decision should be reconsidered. Prevents decisions from becoming dogma by making expiration explicit and graceful. |
| **Actor** (dev platform) | Any entity that executes work processes — a human contributor (Organic Agent), a specific AI model (Probabilistic Agent), or a configured system (Deterministic Agent). Actors are Agents viewed through the lens of process execution. Their 9 Internal Components — particularly Capabilities, Attributes, Skills, and Memory — determine how effectively they can execute a given workflow. Operational engineering designs processes that account for these component differences. |
| **Operational Engineering** | The discipline of designing work processes (workflows, rules, skills, context configurations, agent manifests) so that different actors can execute them effectively. The operational-engineering-agent is the DRI — it owns the methodology for how processes should be designed, not the processes themselves. Parallel to cognitive engineering: CE owns how information is structured for comprehension (output side); OE owns how processes are structured for effective execution (input side). |
| **Cognitive Engineering** | The discipline of structuring information for actual human and agent comprehension. Encompasses review templates, learning briefs, knowledge compression methodologies, progressive disclosure patterns, and cognitive adaptation strategies. The cognitive-engineering-agent is the DRI for this domain — it owns the methodology for how information should be presented, not the information itself. The system evolves through individual and collective feedback loops and progressively personalizes delivery based on how different contributors absorb information. |
| **Progressive Disclosure** | An information architecture principle where content is layered (headline → summary → detail → deep dive) so that a reader can stop at any layer and have a coherent understanding appropriate to that depth. The core structural pattern used in all cognitive engineering templates. |
| **Workspace Contract** | The single configuration file (`syntropy.toml`) that defines a workspace's structure, services, conventions, and behavior. Schema-validated, versioned, and the only config file humans review. Unknown keys are errors. |
| **Workspace Instance** | The `.syntropy/` directory that contains both human-facing artifacts (tasks, system-of-work docs, signals) and machine-generated state (indexes, caches). Follows explicit checked-in vs ignored conventions. |
| **Workspace State** | The structured, machine-readable output of `syntropy state --json` — a hydration contract that provides agents and tools with a complete understanding of the workspace without parsing files or inferring meaning. |
| **PatchSet** | A transactional set of file changes produced by the plan/apply engine. Previewed before application, applied atomically, and reversible. The unit of workspace mutation. |
| **Plan/Apply** | The transactional pattern where structural changes to a workspace are first previewed as a patchset (plan), reviewed by the operator, and then executed atomically (apply). All platform mutations use this pattern. |
| **Blueprint** | A reusable template that defines the structure, files, and configuration for a new workspace component (service, app, crate). Platform-provided blueprints cover standard patterns; projects can define custom blueprints in `.syntropy/system-of-work/templates/`. |
| **Validation Report** | The deterministic, machine-readable output of `syntropy validate --json` — a contract that enumerates all structural violations, dependency issues, and convention drift in a workspace. Each violation has an error code, location, and fix hint. |
| **North Star Layout** | The canonical repository structure that the Syntropy platform targets. Everything in the repo is one of five categories: Platform (reusable foundation), Products (shipped surfaces), Tooling (build/CI/devex), Workspaces (fixtures/templates), and Instance (`.syntropy/`). |
| **Heterogeneous Agent Architecture** | The foundational architecture that treats all system participants — humans (Organic Agents), AI models (Probabilistic Agents), and hardcoded programs (Deterministic Agents) — as first-class Agents sharing equal systemic privileges. Every agent is composed of the same 9 Internal Components (Capabilities, Attributes, Skills, Memory, Internal Context, Internal State, Traits, Policies, Workflows) and is defined by its Decision Profile — how it processes logic to arrive at a conclusion, not what it is made of. |
| **Organic Agent** | An agent whose logic engine is biological/intuitive (a human). Job: to provide creative, intuitive, and high-level strategic direction, driven by human motivation. Key strengths: high-level strategy, moral judgment, creative leaps, contextual wisdom. Key constraints: slow latency, unpredictable, subject to fatigue. Trusted with ultimate authority in the system. Its 9 components are filled with human characteristics — Memory is lived experience, Internal State is emotional/physiological condition, Policies are personal motivations. |
| **Probabilistic Agent** | An agent whose logic engine is machine learning/AI (LLMs, neural networks). Job: to dynamically interpret the world, adapt to unpredictable human behavior, and make logical, context-aware decisions. Key strengths: high adaptability, pattern recognition, natural language understanding, dynamic response. Key constraints: black-box reasoning, prone to drift or hallucination. Trusted with interpretation, never absolute state changes without validation. Its components include Memory (training data + past events), Internal Context (the active prompt/data slice), and Traits (programmed personality biases). |
| **Deterministic Agent** | An agent whose logic engine is procedural code/rules (functions, scripts, state machines). Job: to flawlessly and instantly enforce the rules of the world, manage the math, and execute absolute commands without deviation. Key strengths: 100% reliability, instant execution, mathematically provable correctness. Key constraints: extreme rigidity, fails on unprogrammed edge cases. Trusted with absolute truth. Its Policies component is N/A — it has no goals or motivations, only absolute commands it must follow. |
| **Internal Component** | One of the nine universal building blocks that compose every agent, regardless of type: Capabilities (the Potential), Attributes (the Boundaries), Skills (the Tools), Memory (the History), Internal Context (the Attention), Internal State (the Mindset/Posture), Traits (the Disposition), Policies (the Mission), and Workflows (the Procedure). Defined by job and purpose, never by implementation. |
| **Capabilities** (component) | The Potential — what an actor is fundamentally able to perceive or do. For an Organic Agent: physical ability to see, hear, interact. For a Probabilistic Agent: ability to read situations and recognize patterns. For a Deterministic Agent: ability to execute rule-based logic instantly. |
| **Attributes** (component) | The Boundaries — the absolute, measurable limits of an actor's capabilities. For an Organic Agent: reaction time, fatigue, attention span. For a Probabilistic Agent: context window size, inference latency. For a Deterministic Agent: update frequency, max value caps, rate limits. |
| **Skills** (component) | The Tools — specific, actionable tasks the actor knows how to execute to affect the world. For an Organic Agent: navigate UI, make judgment calls, communicate. For a Probabilistic Agent: classify, summarize, suggest, generate. For a Deterministic Agent: validate, compute, enforce, route. |
| **Memory** (component) | The History — the storage of past experiences, knowledge, and rules used to inform future choices. For an Organic Agent: lived experiences, domain knowledge, past interactions. For a Probabilistic Agent: training data, accumulated event history. For a Deterministic Agent: event logs, configuration, materialized views. |
| **Internal Context** (component) | The Attention — the immediate, active awareness of the present situation; what the actor is focused on right now. For an Organic Agent: what they are actively looking at (they may be blind to adjacent information). For a Probabilistic Agent: the exact data slice being processed for the current decision. For a Deterministic Agent: the active variables being evaluated this instant. |
| **Internal State** (component) | The Mindset/Posture — the actor's current operating mode or condition, which dictates how it reacts to the context. For an Organic Agent: emotional/physiological condition (focused, fatigued, frustrated). For a Probabilistic Agent: cognitive processing phase (assessing, formulating, generating). For a Deterministic Agent: programmed condition (processing, waiting, error, complete). |
| **Traits** (component) | The Disposition — innate, persistent biases that flavor decision-making without changing the actual rules. For an Organic Agent: natural interaction style (cautious, aggressive, delegator). For a Probabilistic Agent: programmed personality (conservative, balanced, domain-tuned). For a Deterministic Agent: static baselines (timeout values, retry counts, priority weights). |
| **Policies** (component) | The Mission — the overarching goals or behavioral guidelines the actor is trying to achieve. For an Organic Agent: personal motivations ("clear my inbox," "train the AI"). For a Probabilistic Agent: core directives ("reduce cognitive load," "keep the user informed"). For a Deterministic Agent: N/A — no goals or motivations, only absolute commands. |
| **Workflows** (component) | The Procedure — the step-by-step logical process used to apply skills to solve a problem. For an Organic Agent: mental routines and practiced tactics. For a Probabilistic Agent: logical evaluation → weigh options → decide sequence. For a Deterministic Agent: strict, unchanging "if this, then that" logic. |
| **Decision Profile** | A characterization of how an agent processes logic to arrive at a conclusion — the meta-layer that sits above the 9 Internal Components, summarizing the pattern by which those components interact. Captures: logic engine type, latency (Attributes), reliability envelope (Capabilities + Skills + Memory), failure mode (Internal State), adaptability (Memory + Capabilities), and cost (Attributes). Decision Profiles enable principled routing decisions about which agent should handle a task. |
| **Boundary of Trust** | The formal boundaries defining what each agent type is trusted to do: Deterministic Agents are trusted with absolute truth, Probabilistic Agents with interpretation (validated before state changes), and Organic Agents with ultimate authority (inputs still validated against rules). In component terms: trust boundaries are calibrated by comparing the agent's Capabilities, Skills, and Memory against the task requirements. |
| **Graceful Degradation** (agent) | The protocol by which agents hand off control when they cannot process a scenario: Probabilistic Agents fall back to Deterministic Agents or escalate to Organic Agents; Deterministic Agents reject with clear errors and escalate; Organic Agent unavailability triggers queuing without blocking the system. Triggered by Internal State transitions (e.g., Probabilistic Agent shifting to "low confidence"). |
| **Trait** (agent system) | A composable set of context, rules, and workflows that an agent inherits in the dev platform agent system. Agents are composed from base traits + domain-specific traits. Distinct from the "Traits" internal component — Trait (agent system) defines *what* an agent owns; Traits (component) describes *innate biases* in how it decides. |
